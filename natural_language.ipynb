{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7172561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ciru\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ciru\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n"
     ]
    }
   ],
   "source": [
    "#Task 1: Sentiment Analysis\n",
    "##Install the transformers library\n",
    "\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "190c8ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1: Sentiment Analysis\n",
      "I love using the Hugging Face library!: POSITIVE (1.00)\n",
      "I'm not very fond of this movie.: NEGATIVE (1.00)\n",
      "The weather is terrible today.: NEGATIVE (1.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "##Import the pipeline function from the transformers library\n",
    "from transformers import pipeline\n",
    "\n",
    "##Initialize a sentiment analysis pipeline\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\")\n",
    "texts = [\"I love using the Hugging Face library!\", \"I'm not very fond of this movie.\", \"The weather is terrible today.\"]\n",
    "sentiment_results = sentiment_analysis(texts)\n",
    "\n",
    "#Print the results\n",
    "print(\"Task 1: Sentiment Analysis\")\n",
    "output_lines = [f\"{text}: {result['label']} ({result['score']:.2f})\" for text, result in zip(texts, sentiment_results)]\n",
    "print('\\n'.join(output_lines))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18de9377",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2: Question Answering\n",
      "Answer: DUMBO, Brooklyn (confidence: 0.49)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 2: Question Answering\n",
    "##Initialize a question answering pipeline\n",
    "question_answering = pipeline(\"question-answering\")\n",
    "context = \"Hugging Face is a company based in New York City. Its headquarters are in DUMBO, Brooklyn.\"\n",
    "question = \"Where is Hugging Face's headquarters located?\"\n",
    "answer = question_answering(question=question, context=context)\n",
    "\n",
    "print(\"Task 2: Question Answering\")\n",
    "print(f\"Answer: {answer['answer']} (confidence: {answer['score']:.2f})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b71145e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3: Named Entity Recognition\n",
      "El: I-PER (1.00)\n",
      "##on: I-PER (1.00)\n",
      "Mu: I-PER (1.00)\n",
      "##sk: I-PER (1.00)\n",
      "Te: I-ORG (1.00)\n",
      "##sla: I-ORG (1.00)\n",
      ",: I-ORG (0.99)\n",
      "Inc: I-ORG (1.00)\n",
      "American: I-MISC (1.00)\n",
      "Pa: I-LOC (1.00)\n",
      "##lo: I-LOC (0.99)\n",
      "Alto: I-LOC (1.00)\n",
      "California: I-LOC (1.00)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 3: Named Entity Recognition\n",
    "##Initialize a named entity recognition pipeline\n",
    "ner = pipeline(\"ner\")\n",
    "text = \"Elon Musk is the CEO of Tesla, Inc., an American electric vehicle and clean energy company based in Palo Alto, California.\"\n",
    "entities = ner(text)\n",
    "\n",
    "print(\"Task 3: Named Entity Recognition\")\n",
    "for entity in entities:\n",
    "    print(f\"{entity['word']}: {entity['entity']} ({entity['score']:.2f})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600ad619",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 and revision a4f8f3e (https://huggingface.co/sshleifer/distilbart-cnn-12-6).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Your max_length is set to 142, but you input_length is only 116. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=58)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4: Text Summarization\n",
      " Natural language processing is a subfield of artificial intelligence that focuses on the interaction between computers and humans through natural language . The goal of NLP is to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful . NLP techniques are used in a wide range of applications, including text analysis, sentiment analysis, machine translation and chatbot development .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Task 4: Text Summarization\n",
    "summarization = pipeline(\"summarization\")\n",
    "text = \"Natural language processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and humans through natural language. The goal of NLP is to enable computers to understand, interpret, and generate human language in a way that is both meaningful and useful. NLP techniques are used in a wide range of applications, including text analysis, sentiment analysis, machine translation, and chatbot development. Recent advances in deep learning have led to significant improvements in the performance of NLP models, making it possible to tackle complex language tasks with greater accuracy and efficiency.\"\n",
    "summary = summarization(text)[0]['summary_text']\n",
    "\n",
    "print(\"Task 4: Text Summarization\")\n",
    "print(summary)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62b03ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in c:\\users\\ciru\\anaconda3\\lib\\site-packages (0.1.99)\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca5724a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46f301c02cb543e9ab8546d45dba252a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/778k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CIRU\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\CIRU\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69baf6d1876c48789859945f71a3fd2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/802k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188ef002f21148e99f3d3a2330702a00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61b010b7d7cb477dbf173818511dc8af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/42.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CIRU\\anaconda3\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "C:\\Users\\CIRU\\anaconda3\\lib\\site-packages\\transformers\\generation_utils.py:1359: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 512 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5: Text Translation\n",
      "Translated text: Hugging Face fournit des modèles et des outils NLP à la fine pointe de la technologie.\n"
     ]
    }
   ],
   "source": [
    "# Task 5: Text Translation\n",
    "# Initialize a text translation pipeline that translates from English to French\n",
    "from transformers import MarianTokenizer, MarianMTModel\n",
    "\n",
    "# Define the model and tokenizer for English to French translation\n",
    "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define a translation function\n",
    "def translate_text(text, model, tokenizer):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=\"max_length\", max_length=40)\n",
    "    translation = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(translation[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "# Text to translate\n",
    "text = \"Hugging Face provides state-of-the-art NLP models and tools.\"\n",
    "\n",
    "# Translate text from English to French\n",
    "translated_text = translate_text(text, model, tokenizer)\n",
    "\n",
    "print(\"Task 5: Text Translation\")\n",
    "print(f\"Translated text: {translated_text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c28779c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 6: Zero-shot Classification\n",
      "Predicted category: technology (confidence: 0.87)\n"
     ]
    }
   ],
   "source": [
    "# Task 6: Zero-shot Classification\n",
    "zero_shot = pipeline(\"zero-shot-classification\")\n",
    "text = \"Tesla unveils its latest electric vehicle, the Cybertruck.\"\n",
    "categories = [\"sports\", \"technology\", \"politics\", \"entertainment\", \"finance\"]\n",
    "result = zero_shot(text, candidate_labels=categories)\n",
    "\n",
    "print(\"Task 6: Zero-shot Classification\")\n",
    "print(f\"Predicted category: {result['labels'][0]} (confidence: {result['scores'][0]:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c175d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
